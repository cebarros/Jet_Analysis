{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60e5e70b-3956-445c-911c-12dbb59b0c14",
   "metadata": {},
   "source": [
    "# Jet Energy Resolution Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0e9ae0-77f6-4b1a-a5e9-cba62ac837f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "import coffea\n",
    "import uproot\n",
    "import hist\n",
    "import vector\n",
    "from coffea import util, processor\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema, BaseSchema\n",
    "from distributed.diagnostics.plugin import UploadDirectory\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import pickle\n",
    "import correctionlib\n",
    "from coffea.analysis_tools import PackedSelection\n",
    "from dask.distributed import Client\n",
    "from scipy.optimize import curve_fit\n",
    "import csv\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bb2a2d-56d6-4c77-abcb-35d78725b849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"pkl_files/QCD_pt_response_NEW.pkl\", \"rb\") as f:\n",
    "    output = pickle.load(f)\n",
    "    \n",
    "for k,v in output.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1119f7b-364a-4503-bc7a-57e39e8beead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output['cutflow'].keys() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa818771-24ff-4df0-b4b4-a94ab99cd3e4",
   "metadata": {},
   "source": [
    "### Loading and Plotting PKL File Output\n",
    "\n",
    "Let's start by plotting the histograms that contain data for the ratio of reconstructed jet $p_{T}$ to generated jet $p_{T}$; we use the `output[\"responses_histogram\"]` key and project it to `dataset` and the variable of interest, such as `.project(\"dataset\", \"pt\")`, `.project(\"dataset\", \"frac\")`, or `.project(\"dataset\", \"eta\")`, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e5aa9b-a273-4cfb-8c41-47d2861f5125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "output[\"responses_histogram\"].project('dataset', 'frac').plot(ax=axs[0], density=True)\n",
    "output[\"responses_histogram\"].project('dataset', 'eta').plot(ax=axs[1], density=True)\n",
    "output[\"responses_histogram\"].project('dataset', 'pt').plot(ax=axs[2], density=True)\n",
    "                                                                  \n",
    "axs[0].legend(frameon=True)\n",
    "axs[1].legend(frameon=True)\n",
    "axs[2].legend(frameon=True)\n",
    "axs[2].set_yscale('log')\n",
    "axs[2].set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b3b1e8-f64c-4390-a51e-f34eb6dbb4c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\".project('dataset', 'frac') numpy shape    ==>    {output['responses_histogram'].project('dataset', 'frac').to_numpy()[0].shape}\")\n",
    "print(f\".project('dataset', 'eta') numpy shape    ==>    {output['responses_histogram'].project('dataset', 'eta').to_numpy()[0].shape}\")\n",
    "print(f\".project('dataset', 'pt') numpy shape    ==>    {output['responses_histogram'].project('dataset', 'pt').to_numpy()[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb920372-dd29-4a97-837b-7e8485e83dbe",
   "metadata": {},
   "source": [
    "Next, we project the `output[\"corrections_histogram\"]` histogram to its corresponding axes as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a75ce5-204f-4c27-ad8b-e2ca5356a1a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "output[\"corrections_histogram\"].project('dataset', 'rho').plot(ax=axs[0], density=True)\n",
    "output[\"corrections_histogram\"].project('dataset', 'npvs').plot(ax=axs[1], density=True)\n",
    "output[\"corrections_histogram\"].project('dataset', 'npu').plot(ax=axs[2], density=True)\n",
    "\n",
    "axs[0].legend(frameon=True)\n",
    "axs[1].legend(frameon=True)\n",
    "axs[2].legend(frameon=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a345d4-7d12-4cdf-9c32-ce944958dbde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\".project('dataset', 'rho') numpy shape    ==>    {output['corrections_histogram'].project('dataset', 'rho').to_numpy()[0].shape}\")\n",
    "print(f\".project('dataset', 'npvs') numpy shape    ==>    {output['corrections_histogram'].project('dataset', 'npvs').to_numpy()[0].shape}\")\n",
    "print(f\".project('dataset', 'npu') numpy shape    ==>    {output['corrections_histogram'].project('dataset', 'npu').to_numpy()[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa6fa85-b05b-4061-bd1a-afc98cef61f0",
   "metadata": {},
   "source": [
    "### Fitting Histograms and Plotting Curves for a Given Transverse Momentum Range\n",
    "\n",
    "In order to add a fit to our historgrams, we start by defining the edges, centers, and widths of the bins for our quantities of interest, which will be the `dataset`, `frac`,`eta`, and `pt`. We also define the define a dataset axis for future use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d5b64a-b171-41db-93bd-04a7b4bc263d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "histogram_1 = output[\"responses_histogram\"]\n",
    "\n",
    "for axis in histogram_1.axes:\n",
    "    print(f\"Axis type: {axis}\\n\")\n",
    "    \n",
    "dataset_axis = histogram_1.axes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09bcd07-b740-47ca-a9cb-0329df14bda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = []\n",
    "bin_centers = []\n",
    "bin_widths = []\n",
    "\n",
    "eras = []\n",
    "\n",
    "for i in range(len(dataset_axis)):\n",
    "    era = dataset_axis[i]\n",
    "    eras.append(era)\n",
    "\n",
    "print(eras)\n",
    "\n",
    "for axis in histogram_1.axes:\n",
    "    bin_edges.append(axis.edges)\n",
    "    bin_centers.append(axis.centers)\n",
    "    bin_widths.append(axis.widths)\n",
    "\n",
    "dataset_bin_edges, frac_bin_edges, eta_bin_edges, pt_bin_edges = bin_edges\n",
    "\n",
    "dataset_bin_centers, frac_bin_centers, eta_bin_centers, pt_bin_centers = bin_centers\n",
    "\n",
    "dataset_bin_widths, frac_bin_widths, eta_bin_widths, pt_bin_widths = bin_widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d005c29c-c604-49cd-aeaa-55091fe35554",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"pt_bin_edges: {pt_bin_edges}\\n\\npt_bin_centers: {pt_bin_centers}\\n\\npt_bin_widths: {pt_bin_widths}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1741a431-b6bc-4ec8-a082-727bfced2de8",
   "metadata": {},
   "source": [
    "Having defined our bin dimensions, we now fit our histograms to a gaussian function and print its relevant parameters, such as its amplitude, mean, and width. It is important to note that we are projecting the $p_{T}$ fraction ratio over the entire dataset through `.project('dataset', 'frac')`, and so the distribution obtained contains the response over its whole respective era. Our next goal will be to create a fit for each $p_{T}$ bin, for each complete era, as this will allow us to obtain the widths (JER) and means (JES) of the graphs as functions of the transverse momentum bins for all four eras. To do so, we will first need to convert our `Hist` objects to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d366018a-3844-4015-adc4-645a29c35949",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gaussian_function(x, amplitude, mean, standard_dev):\n",
    "    return amplitude * np.exp(- (x - mean)**2 / (2. * standard_dev**2))\n",
    "\n",
    "histogram_frac_numpy, bin_edges = histogram_1.project('dataset', 'frac').to_numpy()[0], frac_bin_edges\n",
    "bin_centers = frac_bin_centers\n",
    "frac_xspace = np.linspace(0, 2, 300)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(len(eras)):\n",
    "    normalized_y_vals = histogram_frac_numpy[i] / np.sum(histogram_frac_numpy[i])\n",
    "    popt, pcov = curve_fit(gaussian_function, xdata=bin_centers, ydata=normalized_y_vals)\n",
    "    print(f\"Era: {eras[i]}    |    amplitude: {popt[0]}    |    mean: {popt[1]}    |    stdev: {popt[2]}    |    .project('dataset', 'frac'): {output['responses_histogram'].project('dataset', 'frac').to_numpy()[0].shape}\\n\")\n",
    "    \n",
    "    axs[0].stairs(normalized_y_vals, bin_edges, label=eras[i])\n",
    "    axs[0].set_title(\"$p_T$ Response, Experiment\")\n",
    "    axs[0].set_xlabel(\"Response\")\n",
    "    axs[0].set_ylabel(\"Normalized Counts\")\n",
    "    axs[0].legend(frameon=True)\n",
    "    \n",
    "    axs[1].plot(frac_xspace, gaussian_function(frac_xspace, *popt), label=eras[i])\n",
    "    axs[1].set_title(\"$p_T$ Response, Gaussian Fits\")\n",
    "    axs[1].set_xlabel(\"Response\")\n",
    "    axs[1].set_ylabel(\"Normalized Counts\")\n",
    "    axs[1].legend(frameon=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0413ed26-8d84-479e-b685-624f429cafd1",
   "metadata": {},
   "source": [
    "Our last task will be to record the means and widths of the gaussian fits for all $p_{T}$ bins, and then plot them as functions of the transverse momentum. We will then fit these JES/JER curves to the text files in the `jer_files` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d1fbd3-51c7-44fc-8cf0-4850e8253568",
   "metadata": {},
   "source": [
    "### Obtaining JES and JER Datapoints\n",
    "\n",
    "Before continuing further, lets plot first all transverse momentum bins for each era; this will allow us to see $p_{T}$ distribution more clearly. To start with, we have to define a new histogram projection `.project('dataset', 'pt')` that contains all $p_{T}$ bins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b85b12-c9ca-4f6c-9cff-ad14379faaa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "histogram_2 = output[\"responses_histogram\"]\n",
    "histogram_pt_numpy, bin_edges = histogram_2.project(\"dataset\", \"pt\").to_numpy()[0], pt_bin_edges\n",
    "bin_widths = pt_bin_widths\n",
    "\n",
    "for i in range(len(eras)):\n",
    "    normalized_y_vals = histogram_pt_numpy[i] / (np.sum(histogram_pt_numpy[i]) * bin_widths)\n",
    "    plt.stairs(normalized_y_vals, bin_edges, label=eras[i])\n",
    "    plt.title(\"$p_T$ Distributions\")\n",
    "    plt.xlabel(r\"$p_T$ [GeV]\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.legend(frameon=True)\n",
    "\n",
    "print(f\".project('dataset', 'pt') numpy shape    ==>    {histogram_2.project('dataset', 'pt').to_numpy()[0].shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432893a5-e4af-4ffa-85bb-98086aaab610",
   "metadata": {},
   "source": [
    "Now we define the projection `.project('pt', 'frac')` and plot the fractional transverse momentum response for all eras, for each $p_{T}$ bin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ace7cd5-c22d-418f-8d93-8cb4d6c2a381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "histogram_3 = output[\"responses_histogram\"]\n",
    "histogram_pt_frac_numpy, bin_edges = histogram_3.project(\"pt\", \"frac\").to_numpy()[0], frac_bin_edges\n",
    "\n",
    "color_map = plt.get_cmap('brg', len(pt_bin_centers))\n",
    "    \n",
    "for i in range(len(pt_bin_centers)):\n",
    "    color = color_map(i / len(pt_bin_centers))\n",
    "    normalized_y_vals = histogram_pt_frac_numpy[i] / np.sum(histogram_pt_frac_numpy[i])\n",
    "    plt.stairs(normalized_y_vals, bin_edges, label=f\"${pt_bin_edges[i]} <  p_{{T}}  < {pt_bin_edges[i + 1]}$\", color=color)\n",
    "    plt.title(\"$p_T$ Response, All Eras\")\n",
    "    plt.xlabel(\"Response\")\n",
    "    plt.ylabel(\"Normalized Counts\")\n",
    "    #plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), ncol=3)\n",
    "    \n",
    "print(f\".project('pt', 'frac') numpy shape    ==>    {histogram_3.project('pt', 'frac').to_numpy()[0].shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9585770e-0edd-413e-9cda-1a48018a584f",
   "metadata": {},
   "source": [
    "If we now define one last projection `.project('dataset', 'pt', 'frac')`, we can plot the $p_{T}$ response curves separately for each individual dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0698c5d-2195-4f58-bc44-7ec0656c3858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "histogram_4 = output[\"responses_histogram\"]\n",
    "histogram_dataset_pt_frac_numpy, bin_edges = histogram_4.project(\"dataset\", \"pt\", \"frac\").to_numpy()[0], frac_bin_edges\n",
    "\n",
    "color_map = plt.get_cmap('brg', len(pt_bin_centers))\n",
    "\n",
    "for i, dataset in enumerate(histogram_dataset_pt_frac_numpy):\n",
    "    for j, frac_vals in enumerate(dataset):\n",
    "        color = color_map(j, len(pt_bin_centers))\n",
    "        normalized_y_vals = frac_vals / np.sum(frac_vals)\n",
    "        plt.stairs(normalized_y_vals, bin_edges, label=f\"${pt_bin_edges[j]} <  p_{{T}}  < {pt_bin_edges[j + 1]}$\", color=color)\n",
    "        plt.title(f\"$p_T$ Response, {histogram_4.project('dataset', 'pt', 'frac').axes[0][i]}\")\n",
    "        plt.xlabel(\"Response\")\n",
    "        plt.ylabel(\"Normalized Counts\")\n",
    "    #plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), ncol=3)\n",
    "    plt.show()\n",
    "    \n",
    "print(f\".project('dataset', 'pt', 'frac') numpy shape    ==>    {histogram_4.project('dataset', 'pt', 'frac').to_numpy()[0].shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622c1ea7-6117-41cb-a49a-24fde8e1ae3e",
   "metadata": {},
   "source": [
    "Finally, we fit all response curves of each era to a gaussian, and save their amplitudes, means, widths, and respective uncertainties to a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1bffdf-ac71-4292-aaf6-223c0355022b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "histogram_4 = output[\"responses_histogram\"]\n",
    "histogram_dataset_pt_frac_numpy, bin_edges = histogram_4.project(\"dataset\", \"pt\", \"frac\").to_numpy()[0], frac_bin_edges\n",
    "bin_centers = frac_bin_centers\n",
    "frac_xspace = np.linspace(0, 2, 300)\n",
    "\n",
    "fig, axs = plt.subplots(4, 2, figsize=(20, 20))\n",
    "\n",
    "fit_parameters = {}\n",
    "\n",
    "for i, dataset in enumerate(histogram_dataset_pt_frac_numpy):\n",
    "    era_parameters = []\n",
    "    for j, frac_vals in enumerate(dataset):\n",
    "        normalized_y_vals = frac_vals / np.sum(frac_vals)\n",
    "        popt, pcov = curve_fit(gaussian_function, xdata=bin_centers, ydata=np.nan_to_num(normalized_y_vals))\n",
    "        era_parameters.append((popt, pcov))\n",
    "            \n",
    "        axs[i, 0].stairs(normalized_y_vals, bin_edges)\n",
    "        axs[i, 0].set_title(f\"$p_T$ Response {histogram_4.project('dataset', 'pt', 'frac').axes[0][i]}, Experiment\")\n",
    "        axs[i, 0].set_xlabel(\"Response\")\n",
    "        axs[i, 0].set_ylabel(\"Normalized Counts\")\n",
    "    \n",
    "        axs[i, 1].plot(frac_xspace, gaussian_function(frac_xspace, *popt))\n",
    "        axs[i, 1].set_title(f\"$p_T$ Response {histogram_4.project('dataset', 'pt', 'frac').axes[0][i]}, Gaussian Fits\")\n",
    "        axs[i, 1].set_xlabel(\"Response\")\n",
    "        axs[i, 1].set_ylabel(\"Normalized Counts\")\n",
    "    fit_parameters[histogram_4.project('dataset', 'pt', 'frac').axes[0][i]] = era_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2273820-553f-4036-b6f8-de63f2dfd752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = \"./gaussian_fit_files/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for key, value in fit_parameters.items():\n",
    "    filename = f\"gaussian_parameters_{key}.csv\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    with open(filepath, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['popt', 'pcov'])       \n",
    "        for popt, pcov in value:\n",
    "            writer.writerow([popt, pcov])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972830f7-ab80-46e6-89e4-91b61d84168c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
